<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Hack hack hack...]]></title>
  <link href="http://adamjonas.com/atom.xml" rel="self"/>
  <link href="http://adamjonas.com/"/>
  <updated>2017-04-25T15:54:45-04:00</updated>
  <id>http://adamjonas.com/</id>
  <author>
    <name><![CDATA[Adam Jonas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A Technically Inexperienced Manager]]></title>
    <link href="http://adamjonas.com/blog/a-technically-inexperienced-manager/"/>
    <updated>2017-04-25T19:47:00-04:00</updated>
    <id>http://adamjonas.com/blog/a-technically-inexperienced-manager</id>
    <content type="html"><![CDATA[<p>I&#8217;ve thought deeply about how my technical inexperience impacts my abilities to manage a technical team. I think it&#8217;s a valid concern. I wrote about my thoughts on <a href="http://adamjonas.com/blog/my-take-on-maker-versus-manager/">maker vs manager</a> already, but this is a different beast. I haven&#8217;t been managing technical teams all that long and yet I have a deep rooted belief that I can be effective as an engineering manager in spite of my background.</p>

<p>I have been building teams and managing people for the bulk of my professional career. In the latter half of my twenties I ran a baseball academy in Dominican Republic. We had 30+ teenage athletes, 15 staff, two fields, dormitories, and kitchen. It was a big operation for a kid who spoken broken Spanish and never played the sport professionally. To compensate, I was a tyrant. I made all the calls and I shouldered the whole load. I constantly felt no one was doing enough. I felt like I was the only one who made sure the kids got what they needed. The staff hated me. I didn&#8217;t care. I controlled the daily schedule and the food deliveries. I checked that the grass was cut and the players weren&#8217;t sneaking out past curfew. I was scrappy and I was a hard-ass. In retrospect, I&#8217;m sorry my staff had to pay the the price for my education.  Those years burned me out. I was lonely. I was stressed. I was a single point of failure. I was a terrible version of myself and I knew I&#8217;d never do it that way again.</p>

<p>Part of my growth as a person has been to get past my own insecurities. I learned to be comfortable not knowing the answer. Once I started managing a tech team, it took me a while to understand that really good devs often <strong>don&#8217;t</strong> want any people management responsibilties and so I strive to be their sh!t umbrella. I work to isolate them from the politics and meetings so that they can focus on what they do best &#8211; make magic. I would no doubt be more valuable if I had more reps, but my focus has been to strive to understand how the systems fit together and ask the right questions rather than lord over the implementation.</p>

<p>I can&#8217;t fake my background. I learned to code late. It is a constraint I can&#8217;t change. While I can work to refine my instincts and up my skills, I&#8217;m at peace with the fact I will never be the CTO. At least not the traditional kind. As I age and better understand myself, I&#8217;ve learned I am more effective when learning from my reports rather than handing down instructions. Even though it doesn&#8217;t feel like it on the subway, <a href="http://www.medicaldaily.com/human-brain-hardwired-acts-kindness-vagus-nerve-activated-during-empathy-313020">humans are hardwired for kindness</a>. People energize me and I find satisfaction in helping a group discover cohesion. There will always be more to learn. The tech changes and so do the people. Businesses evolve demanding different kinds of leaders. But when we put people first, I&#8217;ve found the other pieces fall into place because trust and rapport create forgiveness and understanding. Or at least that&#8217;s what my experience has taught me.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Intro to React]]></title>
    <link href="http://adamjonas.com/blog/intro-to-react/"/>
    <updated>2017-04-07T11:30:00-04:00</updated>
    <id>http://adamjonas.com/blog/intro-to-react</id>
    <content type="html"><![CDATA[<h2>React event</h2>

<ul>
<li>similar to normal <a href="https://facebook.github.io/react/docs/handling-events.html">event handling</a> (responds to target and such, but has other properties)</li>
</ul>


<h2>Refs and the Dom</h2>

<ul>
<li><a href="https://facebook.github.io/react/docs/refs-and-the-dom.html">ref documentation</a></li>
</ul>


<h2>Props</h2>

<ul>
<li>They are the mechanism used in React for passing data from parent to child components</li>
<li>Props can’t be changed from inside the component; they are passed and “owned” by the parent.</li>
</ul>


<h2>State</h2>

<ul>
<li>React’s components can have mutable data inside this.state.</li>
<li>when the state is updated, the component triggers the reactive rendering, and the component itself and its children will be re-rendered. As mentioned, this happens very quickly due to React’s use of a virtual DOM.</li>
</ul>


<h2>Component to action to store</h2>

<ul>
<li> the store is subscribed to the action</li>
<li> components subscribed to stores -> re-render</li>
<li><p> props are immutible -> given the state of the application, what doe the component look like?</p></li>
<li><p>?what is the value of the actions step -> ususually just passing through to the store</p></li>
<li><p>user inputs triggers the action</p></li>
<li>inputs into the system -> actions</li>
<li>action updates the state</li>
<li><p>which updates the components</p></li>
<li><p>store is more flexibile than backbone collections and models</p></li>
<li>based on the change what literal DOM manipulations are needed -> taken care of virtual DOM</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How Linux Works: What Every Superuser Should Know]]></title>
    <link href="http://adamjonas.com/blog/how-linux-works-what-every-superuser-should-know/"/>
    <updated>2017-04-05T12:13:00-04:00</updated>
    <id>http://adamjonas.com/blog/how-linux-works-what-every-superuser-should-know</id>
    <content type="html"><![CDATA[<h2>Posix shell and Utilities</h2>

<ul>
<li>from <a href="http://shellhaters.org/talk">Shell Hater&#8217;s handbook with Ryan Tomayko</a></li>
<li><a href="http://shellhaters.org/">posix docs</a></li>
</ul>


<h2>fork() &amp; exec()</h2>

<ul>
<li>When running exec() programs, you are forking a shell and running it on that</li>
<li><a href="https://www.bottomupcs.com/fork_and_exec.xhtml">Fork and exec</a></li>
<li><a href="http://askubuntu.com/questions/428458/why-do-shells-call-fork">Why do shells call fork?</a>

<ul>
<li>exec can only run one thing. So shell creates the child shell runs exec and then returns.</li>
</ul>
</li>
<li>fork() clones the current process, creating an identical child. exec() loads a new program into the current process, replacing the existing one. <a href="http://unix.stackexchange.com/questions/179604/how-do-fork-and-exec-work">From</a></li>
</ul>


<h2>Time slice</h2>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Preemption_(computing">time slice</a>#Time_slice) managed by the scheduler of the CPU. Time slices are <a href="https://superuser.com/a/684394">variable</a> -> need this to keep the illusion of concurrency(having multiple processes at the same time) and multi-tasking, but with one core there is no possibility of doing paralellism.</li>
</ul>


<h2>Builtins</h2>

<ul>
<li>(wikipedia)[https://en.wikipedia.org/wiki/Shell_builtin]

<ul>
<li>executed directly in the shell itself, instead of an external executable program which the shell would load and execute.</li>
<li>Shell builtins work significantly faster than external programs, because there is no program loading overhead.</li>
<li>most notable example is <code>cd</code></li>
<li><code>cd</code> has to be a builtin because the shell itself needs to change its &#8220;cwd&#8221; - current working directory - not a sub-process. The goal of &#8220;cd&#8221; is to change the current working directory of the shell itself, and that can&#8217;t be accomplished from a child process without a lot of special hackery which would end up being more complex than the builtin. <a href="https://www.quora.com/Unix-Why-is-cd-a-built-in-command-in-the-shell-and-not-an-executable-program-like-the-command-ls">from</a>

<ul>
<li>great explanation on how it came to be with a quote from <a href="http://unix.stackexchange.com/a/38819">Dennis Ritchie</a></li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Memory Management</h2>

<ul>
<li>swap -> using the hard disk as RAM</li>
<li>A <a href="https://en.wikipedia.org/wiki/Page_table">page table</a> is the data structure used by a virtual memory system in a computer operating system to store the mapping between virtual addresses and physical addresses. Virtual addresses are used by the accessing process, while physical addresses are used by the hardware, or more specifically, by the RAM subsystem.</li>
</ul>


<h2>Tree</h2>

<ul>
<li><a href="https://superuser.com/questions/359723/mac-os-x-equivalent-of-the-ubuntu-tree-command">tree</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vimmin]]></title>
    <link href="http://adamjonas.com/blog/vimmin/"/>
    <updated>2017-04-04T15:37:00-04:00</updated>
    <id>http://adamjonas.com/blog/vimmin</id>
    <content type="html"><![CDATA[<p>Command-T was killing me. Vim was built against the system ruby while
the command-t plugin was set to the default. So I had to jump through a
few hoops described <a href="https://github.com/wincent/command-t/issues/228">here</a>. A pain. Done though.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[More Ops Notes]]></title>
    <link href="http://adamjonas.com/blog/more-ops-notes/"/>
    <updated>2017-03-29T16:18:00-04:00</updated>
    <id>http://adamjonas.com/blog/more-ops-notes</id>
    <content type="html"><![CDATA[<h2>Network partitioning causing exchange issues on rabbitmq</h2>

<ul>
<li>this was after netowrk maintenance</li>
<li>solution was to delete exchange which then is automatically added
back <a href="https://github.com/rabbitmq/rabbitmq-server/issues/887#issuecomment-290177962">documented here</a></li>
</ul>


<h2>Ubuntu 16</h2>

<ul>
<li>ubuntu 16 doesn&#8217;t ship with upstart so sysctld is what we&#8217;ll use to
control services. <a href="https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units">systemctl commands</a>

<ul>
<li>can also run from <code>/etc/init.d/service start</code></li>
</ul>
</li>
<li>rsyslog is what we use to get the logs to papertrail</li>
<li>used the oracle version of Java 8</li>
</ul>


<h2>Digital ocean</h2>

<ul>
<li>backups (auto) are different than snapshots (not auto) and different
in pricing as well</li>
</ul>


<h2>Chef</h2>

<ul>
<li><a href="https://docs.chef.io/ohai.html">ohai</a></li>
<li><a href="https://docs.chef.io/chef_shell.html"><code>chef-shell</code></a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Project Aristole]]></title>
    <link href="http://adamjonas.com/blog/project-aristole/"/>
    <updated>2017-03-27T11:49:00-04:00</updated>
    <id>http://adamjonas.com/blog/project-aristole</id>
    <content type="html"><![CDATA[<ul>
<li><a href="https://www.nytimes.com/2016/02/28/magazine/what-google-learned-from-its-quest-to-build-the-perfect-team.html?_r=0">Quest to build the perfect team</a></li>
</ul>


<h2>Reading Notes</h2>

<ul>
<li>decentralized control</li>
<li>manager surveys

<ul>
<li>different mediums to collect feedback</li>
</ul>
</li>
<li>no exact patterns</li>
<li>rapport building -> chit chat, care about others as people as much
as co-workers

<ul>
<li>social sensitivity

<ul>
<li>reading the <a href="http://socialintelligence.labinthewild.org/mite/">Reading the Mind in the Eyes test</a></li>
</ul>
</li>
<li>trust</li>
</ul>
</li>
<li>groups norms are stronger than the individual, even if the
individual is strong, driven and accomplished</li>
<li>?what is data of a strong group?</li>
<li>following up on hurtful interactions (saying the things that go
unsaid)</li>
<li>Manager:

<ul>
<li>humility, my team is smarter than me -> vulnerability</li>
<li>fulfillment of creating a great team</li>
<li>setting communication norms</li>
<li>empathy norms and quick follow up</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crash Course DevOps]]></title>
    <link href="http://adamjonas.com/blog/crash-course/"/>
    <updated>2017-03-20T11:12:00-04:00</updated>
    <id>http://adamjonas.com/blog/crash-course</id>
    <content type="html"><![CDATA[<h2>Wires, cables and WiFi</h2>

<ul>
<li>Bits sent as light beams, no signal loss

<ul>
<li>faster than copper</li>
</ul>
</li>
<li>WiFi is radio and then translated into physical bits over the wires</li>
<li>Bitrate -> bits per second -> how fast it can transmit</li>
<li>bandwidth -> how much data can you receive over a period of time</li>
<li><p>latency -> how long it takes, more hops to talk to Seiji than
Kaitlin in the next room; ping time * distance</p></li>
<li><p><code>traceroute</code> to see hops</p></li>
</ul>


<h2>IP addresses and DNS</h2>

<ul>
<li>ISP</li>
<li>IP is a unique address

<ul>
<li>IPv4 - 4 billion unique addresses isn&#8217;t enough

<ul>
<li>32 bits, 8 octets</li>
<li>32 bits long, 8 bits for each part of each address</li>
<li>DHCP -> obtaining a lease renewal process on your network.</li>
<li>to the outside world, Flatiron has the same IP provided
by ISP</li>
<li>router provides guests with temporary IP depending on how long
your lease renewal is set</li>
<li>renegotiate IP
?- subnet mask</li>
<li>255.255.255.255 is the max it could go, based on the octet</li>
<li>static IP -> unique in the world</li>
<li>private IP -> re-use private IP addresses behind networks</li>
</ul>
</li>
</ul>
</li>
<li><p> IPv6 - 128 bits instead of 32</p>

<ul>
<li>hex representation to prevent us running out of static IPs</li>
<li><p>DNS servers are split up in TLDs</p>

<ul>
<li>DNS on a router</li>
</ul>
</li>
<li><p>google&#8217;s DNS will break it up by the TLD and domain</p></li>
<li><a href="http://www.macworld.com/article/2824564/slow-internet-edit-your-dns-settings.html">google DNS</a> versus open DNS</li>
<li>?www doesn&#8217;t mean anything any more, just another subdomain</li>
<li>?CS of how the domain names at the DNS are stored?</li>
</ul>
</li>
<li><p> TTL</p>

<ul>
<li>this record will expire at X time</li>
<li>set TTL to an hour, it won&#8217;t have to look it up for an hour</li>
<li>DNS propagation</li>
</ul>
</li>
<li><p>DNS -> record type</p>

<ul>
<li>A record -> address</li>
<li>maps the word name the domain to a physical IP address</li>
<li>PTR -> pointer -> the reverse, input IP and get the domain</li>
<li>FQDN -> A fully qualified domain name (<a href="http://stackoverflow.com/questions/19480767/domain-names-with-dots-at-the-end">FQDN</a>) is the complete domain name for a specific computer, or host, on the Internet.

<ul>
<li>Host name is gmail and .com is the TLD</li>
</ul>
</li>
<li>CNAME -> mail.google.com is a CNAME of googlemail.l.google.com.

<ul>
<li>A records should be unique</li>
</ul>
</li>
<li>why is there a dot at the end?

<ul>
<li>it is an absolute as opposed to the relative address</li>
</ul>
</li>
<li>want multiple MX records, redudency strategy</li>
</ul>
</li>
</ul>


<h2>Packet, routers and reliability</h2>

<ul>
<li>fault tolerant</li>
<li>TCP</li>
<li><p>?How do they determine the route?</p>

<ul>
<li>routers own the ISP and the companies that own them</li>
</ul>
</li>
<li><p>traceroute domain.com</p></li>
<li><p>wireshark is a GUI of <a href="https://danielmiessler.com/study/tcpdump/#gs.9p=ZVMQ"><code>tcpdump</code></a></p></li>
<li><p>IP address can change and it has a serial number or a MAC address
(hardware address)</p></li>
</ul>


<h2>HTTP &amp; HTML</h2>

<ul>
<li>SSL and TLS (successor)

<ul>
<li>http listens on 80 and https listens on 443</li>
<li>sslv3 has been deprecated</li>
</ul>
</li>
<li>certificate authority vouches for site</li>
<li>OpenSSL generates keys, authority will sign that</li>
<li>self-signed certs like for nagios or letsencrypt will work fine</li>
<li>SSLS

<ul>
<li>discrete logorithm problem</li>
</ul>
</li>
<li>handshake process -> how to keep box locked and send secret

<ul>
<li>put treasure in box, lock box, send to friend</li>
<li>friend puts lock on box, sends it back</li>
<li>I remove lock from box and send back</li>
<li>friend unlocks box</li>
</ul>
</li>
<li>SSH

<ul>
<li>ssh forwarding sends private key along</li>
<li>asymetric only used for authentication</li>
<li>symetric is then used for encryption and decryption</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Bcrypt">bcrypt</a> is what we use for email</li>
</ul>


<h2>DDoS</h2>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Domain_Name_System#DNS_resolvers">DNS resolvers</a> to amplify attack</li>
</ul>


<h2>DevinOps in review</h2>

<ul>
<li><a href="https://github.com/thiagopradi/octopus">Octopus gem</a> -> pooling, load balance select statements to read only
replicas</li>
<li>DB sharding

<ul>
<li>complex SQL joins, will put different tables in different DBs</li>
<li>replication</li>
</ul>
</li>
<li>floating IPs points to the master

<ul>
<li>static IP never changes</li>
<li>use floating IPs rather than DNS because of propogation</li>
</ul>
</li>
<li>usernames:

<ul>
<li>if you have a server on linux it should not be running on root</li>
<li>if it&#8217;s a system process then it would be ok to run on root</li>
<li>postgres is run as the postgres user

<ul>
<li>apache is run by deployer and passenger -> how ruby achieves
paralellization (a module for apache)</li>
</ul>
</li>
<li>deployer for Ironboard -> easy way to manage keys</li>
<li>how owns the process, who owns the directory where the config
files lives</li>
</ul>
</li>
<li><code>etc/passwd</code> -> all the users on the box and who is logged in</li>
<li>every service that has a port open to the internet it should have
its own user</li>
<li>username is usually the service name</li>
<li><code>/var</code> is usually the log directory</li>
<li><code>/etc</code> is usually the config directory</li>
<li>WAL-E

<ul>
<li>ship our binary logs we sent to s3</li>
<li><a href="https://en.wikipedia.org/wiki/Write-ahead_logging">write ahead logs</a> -> must be complete before actually modifies the
DB with a transaction. This is the mechanism for rollbacks.

<ul>
<li>master just sends the write-ahead logs to the slave which then
just replays them</li>
</ul>
</li>
</ul>
</li>
<li>Backups

<ul>
<li>take a base and then the have these WAL backups and send them off
and it will apply all the deltas</li>
<li>can give us point in time restoration</li>
<li>these logs will fill up our disk</li>
<li>? how long do we keep WAL-E</li>
<li>interface for deleting backups, s3 logs</li>
<li>config of pg is <code>pg_hba.conf</code></li>
<li>script to switch over primary/replication script turns <code>recovery.conf</code> to <code>recovery.done</code></li>
<li><code>failover.sh</code> on the other replica as root

<ul>
<li>breaks replication, now need to configure replication on the new
replication server</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Iptables">iptables</a> -> firewall</li>
</ul>
</li>
</ul>


<h2>Permissions</h2>

<ul>
<li>User, Group, World -> multiple users on the same machine, make sure
processes don&#8217;t do stuff they aren&#8217;t supposed to</li>
<li>chmod 755, 644</li>
<li>all directories have to be 7

<ul>
<li>directories point to other files</li>
</ul>
</li>
<li>cd is a program that takes a directory (file) as an argument and
executes it</li>
<li><code>etc/sudoers</code> -> determines who has root permissions; visudo -> creates a backup and prevents brackage</li>
<li><code>useradd</code> give them a shell and name the user; want to add to the
chef script</li>
</ul>


<h2>load balancer</h2>

<ul>
<li>front-end is learn.co, terminating SSL, in the</li>
<li>backend -></li>
<li>should be root on</li>
</ul>


<h2>Debugging</h2>

<ul>
<li><code>passenger-status --show=requests</code></li>
<li><code>passenger-status</code></li>
</ul>


<h2>Automatic provisioning</h2>

<ul>
<li><a href="https://github.com/digitalocean/doctl">doctl</a></li>
<li><a href="https://github.com/petems/tugboat">tugboat</a></li>
</ul>


<h2>cron</h2>

<ul>
<li>sends mail</li>
</ul>


<h2>IDE backend</h2>

<ul>
<li>backend application -> IDE umbrella</li>
<li>main one is learn-ide-server cookbook</li>
<li>different chef servers</li>
<li>wombat</li>
<li>traffic cop</li>
<li>elixir-build01 -> build elixir on server because linux</li>
<li>new server needs to be added to <a href="https://github.com/flatiron-labs/students-chef-repo/tree/master/cookbooks/learn-ide-haproxy">HAproxy</a></li>
<li>lb -> <code>balance url_param token</code> hashing algorithm that determines
which server the IDE connects to based on their Learn oauth token. (Optimization -> make hashing algo
more granualar so that if a machine gets taken out the rotation, the
othere aren&#8217;t rebalanced as well</li>
<li>Load balance assignment is determined by dynect traffic management

<ul>
<li>own health monitoring</li>
</ul>
</li>
<li><a href="https://www.gluster.org/">gluster</a> is fancy NFS

<ul>
<li>RAID -> redundant array of independent disks</li>
</ul>
</li>
<li><a href="https://coreos.com/rkt/">rkt</a></li>
<li>PTY - psuedoterminal, terminal emulator, connect to an arbitrary shell</li>
<li>inotify -> FS event watcher</li>
<li>containerization

<ul>
<li><a href="https://en.wikipedia.org/wiki/Aufs">aufs</a> loser -> <a href="https://en.wikipedia.org/wiki/UnionFS">unionfs</a> winner that was merged into linux</li>
</ul>
</li>
<li>? do you bump archived tar&#8217;ed files when you archive again</li>
</ul>


<h2>IDE Umbrella</h2>

<ul>
<li>for adding IDE server (<a href="https://github.com/flatiron-labs/ide_umbrella/blob/master/config/prod.exs">node list</a>)</li>
<li>dependencies in <code>mix.exs</code>; <a href="https://github.com/ninenines/cowboy">cowboy</a> is the webserver, <a href="https://github.com/devinus/poolboy">poolboy</a></li>
<li>applications are like slightly fancy supervisors, <a href="https://github.com/bitwalker/distillery">distillery</a> release packaging</li>
<li><code>mix deps.get</code> -> get dependencies</li>
<li><code>iex -S mix</code></li>
<li><code>:cowboy.start</code> -> erlang library, cowboy is lib which is an atom</li>
<li><code>gen_server</code>, an abstraction on top of processes in general

<ul>
<li>provides state and a little behavior</li>
</ul>
</li>
<li><code>agent</code> is just for state</li>
<li>every connection gets its own process</li>
<li>distillery builds them

<ul>
<li>release -> full replacement of previous release, must restart</li>
<li>upgrade -> release plus upgrade instructions, relup file, modify
the code in memory -> hotswap; preferable to release</li>
<li><code>mix edeliver version qa</code></li>
<li><code>mix edeliver version production</code></li>
<li><code>mix edeliver build release</code></li>
<li><code>mix edeliver deployer release to qa</code></li>
<li><code>mix edeliver restart qa</code></li>
<li><code>bin/ide start</code></li>
<li><code>bin/ide attach</code> -> quit with ^D, not ^c (will kill process)</li>
<li><code>bin/ide remote_console</code></li>
<li><code>mix edeliver build upgrade --with=0.1.0+232424323-hdhfd</code></li>
<li><code>mix edeliver deploy upgrade to qa</code> -> will prompt for version
number</li>
</ul>
</li>
</ul>


<h2>Chef</h2>

<ul>
<li>server provisioning

<ul>
<li>consistency, automation</li>
</ul>
</li>
<li>inheritance in the cookbooks, base cookbook -> security</li>
<li>like ruby base cookbooks</li>
<li><a href="https://blog.chef.io/2013/12/03/doing-wrapper-cookbooks-right/">wrapper cookbook</a>, like forking a cookbook without modifying it

<ul>
<li>increasing levels of abstraction</li>
</ul>
</li>
<li>conventions of chef aren&#8217;t very clearly defined</li>
<li>differences between recipes and cookbooks?</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elastic Search]]></title>
    <link href="http://adamjonas.com/blog/elastic-search/"/>
    <updated>2017-03-10T11:38:00-05:00</updated>
    <id>http://adamjonas.com/blog/elastic-search</id>
    <content type="html"><![CDATA[<h2>Intro</h2>

<p>&#8220;elastic search is full text sreach engine, non-relational DB, analytics engine&#8221;</p>

<ul>
<li>has clustering and managed over REST</li>
<li><p>Suggest Explicit mapping</p></li>
<li><p>keywords -> non-analyzed data</p></li>
<li><p>full text -> analyzed</p></li>
<li><p>filters -> will need <code>bool</code> then <code>filters</code></p></li>
</ul>


<h2>relevance -> score meta data field for document match</h2>

<ul>
<li>things are ranked</li>
<li>filters are faster and don&#8217;t have relevance (so if you don&#8217;t care, go with fiters)</li>
<li>can boost relevance</li>
</ul>


<h2>multi-index multi-type</h2>

<ul>
<li>lots of power</li>
</ul>


<h2>Aggregation -> group by on steroids</h2>

<ul>
<li>SQL: group by the bucket</li>
<li>aggregator -> can do nested group by and data retrieval</li>
</ul>


<h2>Managing elastic search</h2>

<ul>
<li>clustering

<ul>
<li>odd number of nodes bigger than 1

<ul>
<li>3 shards and replication</li>
<li>a third node can shuffle the shards and the replicas</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>ELK Stack</h2>

<ul>
<li>elastic search, logstash, and kubana</li>
<li>logstash

<ul>
<li>want to parse and stash log data</li>
</ul>
</li>
<li>kubana

<ul>
<li>front end visualizer</li>
</ul>
</li>
<li>now beats added -> lightweight, written in go -> for shipping</li>
</ul>


<h2>Split Brain issue</h2>

<ul>
<li><a href="http://blog.trifork.com/2013/10/24/how-to-avoid-the-split-brain-problem-in-elasticsearch/">HOW TO AVOID THE SPLIT-BRAIN PROBLEM IN ELASTICSEARCH</a></li>
</ul>


<h2>Tinc</h2>

<ul>
<li>VPN -> encrypts traffic between servers</li>
</ul>


<h2>Setting up elastic search</h2>

<ul>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-16-04">setting up a elasticsearch cluster on ubuntu</a></li>
<li>used a ruby case statement to set the master versus the replicas up</li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html">shards, replicas, documents explained</a></li>
<li><a href="https://qbox.io/blog/launching-and-scaling-elasticsearch">Thoughts on Launching and Scaling Elasticsearch</a></li>
<li><a href="https://qbox.io/blog/optimizing-elasticsearch-how-many-shards-per-index">optimizing sharding</a>

<ul>
<li><code>A good launch point for capacity planning is to allocate shards with a factor of 1.5 to 3 times the number of nodes in your initial configuration. If you're starting with 3 nodes, then we recommend that you specify at most 3 x 3 = 9 shards.</code></li>
<li><code>We reiterate that shards consume resources and require processing overhead.</code></li>
</ul>
</li>
<li>needed to bump vm.max_map_count according to <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html">these instructions</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-with-ufw-on-ubuntu-16-04">UFW</a> -> wasn&#8217;t needed in the end</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Preparing Data for Machine Learning]]></title>
    <link href="http://adamjonas.com/blog/preparing-data-for-machine-learning/"/>
    <updated>2017-03-10T10:02:00-05:00</updated>
    <id>http://adamjonas.com/blog/preparing-data-for-machine-learning</id>
    <content type="html"><![CDATA[<h2>Why machine learning - you can predict the future</h2>

<ul>
<li>Explosion of data, more available than ever</li>
<li>sheer processing power available at a reasonable price point</li>
</ul>


<h2>Data Preparation Tools</h2>

<ul>
<li>Rstudio -> data prep and execute the machine learning</li>
<li>jupyter notebooks -> python in the cloud</li>
<li>excel -> stick with the tools you know</li>
<li>azure machine learning studio</li>
<li>scikit learn (competitor to r studio) for python</li>
<li>relational database tools (SQL queries)</li>
<li>sed / awk</li>
<li>python, r, sql most common languages to clean up data</li>
</ul>


<h2>Data Cleaning</h2>

<ul>
<li>missing values in data or repeating values in data (blanks, null,
n/a, unknown, 999999)</li>
<li>what&#8217;s your business goal?

<ul>
<li>SPCA - can you help us predict what animals won&#8217;t get adopted?</li>
<li>got enough data to be significant, you can delete rows -> not
always an option</li>
</ul>
</li>
<li>can substitute a specific value (can go with a worst case
scenario)</li>
<li>fill forward and fill backwards based on the last value we read ->
going to have to write code</li>
<li>R is.na()</li>
<li><p>python pandas.fillna(), pandas.isnull()</p></li>
<li><p>excel tips -></p>

<ul>
<li>select individual columns, go to special, select blanks (will
select every blank cell) and you can enter a value</li>
</ul>
</li>
<li><p>repeated values</p>

<ul>
<li>causes a bias in the data</li>
<li>duplicate row vs duplicate IDs</li>
<li>r duplicated()</li>
<li>python dataframe.drop_duplicates</li>
<li>SQL DISTINCT or correctlated queries</li>
<li>correlated subquery -> if the rows are the same but the IDs are different when you find
two identitical records and delete the one with the lower ID
number</li>
</ul>
</li>
</ul>


<h2>Data Transformation</h2>

<ul>
<li>Decomposition

<ul>
<li>the more you know about the data, the better</li>
<li>one column represents two or more values (like addresses lumped
together and finding the city and state)</li>
<li>return a 1 or 0 to represented spayed and nuetered</li>
</ul>
</li>
<li><p>Aggregation</p>

<ul>
<li>how many copies of different books to keep in stock?</li>
<li>don&#8217;t want the day it was sold, want total number of books sold
per wk/mon x date</li>
<li>select count(*) from sales group by (books sold per period)</li>
</ul>
</li>
<li><p>Scaling</p>

<ul>
<li>predict how long a patient admitted the flu will need to stay in
the hospital</li>
<li>because the age has a wider varience in age you don&#8217;t see the
lower differences like temperatute

<ul>
<li>create ranges -> normalizing, standardizing</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Conclusion</h2>

<ul>
<li><p>Training data versus test data</p>

<ul>
<li>subject matter experts become important as they need to undetr</li>
<li>tumors -> which do you want, one with more false positives and one
with more false negatives</li>
</ul>
</li>
<li><p>slides at <code>aka.ms/confooml</code></p></li>
<li>data science and machine learning essentials</li>
<li>cleaning data with python</li>
<li>building your first machine learning experiment</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Soul in The Machine - Developing for Humans]]></title>
    <link href="http://adamjonas.com/blog/the-soul-in-the-machine-developing-for-humans/"/>
    <updated>2017-03-09T13:07:00-05:00</updated>
    <id>http://adamjonas.com/blog/the-soul-in-the-machine-developing-for-humans</id>
    <content type="html"><![CDATA[<p>With Christian Heilmann</p>

<h2>Machines vs. Humans</h2>

<ul>
<li>machines don&#8217;t get tired or make mistake as they fatigue</li>
<li>law is boring and machines don&#8217;t get bored</li>
<li>The future of employement -> company secretaries</li>
<li>machines handle grunt work and humans handle human decisions -> the
more abstract the less likely you are to be replaced by a computer</li>
<li>the more predictable we are as programmers, the more likely we are
going to be replaced</li>
<li>AI software that makes AI software</li>
<li>past being factory workers and finding the way to add value</li>
<li>the saddest aspect of life right now is that science gathers
knowledge faster than society gathers wisdom.</li>
<li>just making money isn&#8217;t enough anymore</li>
<li>Orwell predicted cameras everyone but didn&#8217;t predict we would buy the camera</li>
<li>&#8220;Technological progress has merely provided us with more efficient
means for going backwards.&#8221; -> Aldous Huxley</li>
<li>&#8220;the power of big data and psychographics&#8221;</li>
<li>inclusive design set that microsoft released</li>
<li>it&#8217;s not about allowing access but avoiding barriers</li>
<li>spotlight - show me my documents larger than 20 pages</li>
<li>netflix -> fast movement can be compressed more than slow movement</li>
<li>Aipoly -> identify objects on the phone, not running on the internet</li>
<li>facebook open sourced identifying objects</li>
<li>AI lip reading for 46% accuracy, humans have 12% accuracy</li>
<li>imagenet and open images dataset -> image data sets, properly
trained data sets to play with</li>
<li><code>captionbot.ai</code></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Intro to DNS]]></title>
    <link href="http://adamjonas.com/blog/intro-to-dns/"/>
    <updated>2017-03-09T11:00:00-05:00</updated>
    <id>http://adamjonas.com/blog/intro-to-dns</id>
    <content type="html"><![CDATA[<p>With Maarten Balliauw</p>

<ul>
<li>people know should more about DNS and the http level</li>
</ul>


<h2>DNS 101</h2>

<ul>
<li><p>How the internet works</p>

<ul>
<li>IPv4 or IPv6</li>
<li>Check own operating system files to see if the host file has a
record is known</li>
<li>will check the DNS cache for the local machine</li>
<li>OS will ask the router and check its own host file and DNS cache</li>
<li>same process for the ISP</li>
<li>the ISP will then go to the root server, address of the
authoritative server</li>
<li><p>6 hubs look ups</p></li>
<li><p><code>nslookup google.com</code></p></li>
<li><p><code>dig A google.com +trace</code></p></li>
<li><p>two types of servers</p>

<ul>
<li>authorative (owns the domain)</li>
<li>cache (recursor) -> resolves the domain for you</li>
</ul>
</li>
<li>DNS protcol designed in 1983

<ul>
<li>designed to map a domain name to an IP address</li>
<li>added TXT records and IPv6</li>
</ul>
</li>
<li>TLD managed by separate organizatons (verisign, canadian internet
registrartion authority)

<ul>
<li>all make their own rules e.g. need to be a canadian to be a .ca
domain name, transfer rules</li>
</ul>
</li>
<li>hierarchical system:

<ul>
<li>hit <code>.</code> first</li>
<li>then TLD like <code>org, com, ca</code></li>
<li>can also create maps within a specific domain and could create
own hierarchy like google does</li>
</ul>
</li>
<li>caches

<ul>
<li>TTL -</li>
<li>cannot clear cache at ISP</li>
<li>keep the old IP address to maintain both</li>
</ul>
</li>
</ul>
</li>
<li><p>DNS zones</p>

<ul>
<li>UDP protocol</li>
<li>only 13 root servers across the world</li>
<li><code>root-servers.org</code></li>
<li>$100k/yr to get own TLD</li>
<li><p>? where does the money for those fees go for buying a TLD?</p></li>
<li><p>a text file and are hierarchical</p></li>
<li>SOA -> start of authority</li>
<li><p>Name of authoritive master name server (NA)</p></li>
<li><p>CNAME - redirect at the DNS record</p></li>
<li>MX - find mail server at specific address</li>
<li>TXT - validate domain ownership/spam rules</li>
<li>SRV - descibes a service type and port (like for in network
printer)</li>
<li><p>PTR - reverse DNS</p></li>
<li><p>zone transfers</p>

<ul>
<li>most IPs require more than 1 nameserver</li>
<li>master name server and that will sync with slave nameservers</li>
<li>no authentication and may expose internal services</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Security</h2>

<ul>
<li>old protocol</li>
<li>cache poisoning</li>
<li>DNSSEC - checks the origin - certificate chain</li>
<li><p>most modern browsers are checking for DNSSEC records</p></li>
<li><p>DDoS</p>

<ul>
<li>lots of open resolvers out there</li>
<li>DNS amplication for DDos</li>
<li>disable recursion</li>
</ul>
</li>
</ul>


<h2>DNS in application archtecture</h2>

<ul>
<li>DNS failover and load balancing</li>
<li>add multiple DNS records -> will be a poor man&#8217;s load balancer
because it will return an random record</li>
<li>intelligence DNS server (CNS)</li>
<li>configuration in DNS

<ul>
<li>use DNS as a configuration store</li>
<li>DNS record could point to a TXT value</li>
</ul>
</li>
<li>service discovery</li>
</ul>


<h2>DNS for fun and profit</h2>

<ul>
<li><p>Abusing DNS</p>

<ul>
<li>public hotspots</li>
<li>proxy server translating HTTP</li>
</ul>
</li>
<li><p>iodine - same HTTP over DNS - tunnel traffic</p>

<ul>
<li><code>code.kryo.se/iodine</code></li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[7 righteous fights]]></title>
    <link href="http://adamjonas.com/blog/7-righteous-fights/"/>
    <updated>2017-03-09T10:03:00-05:00</updated>
    <id>http://adamjonas.com/blog/7-righteous-fights</id>
    <content type="html"><![CDATA[<p>With Heidi Waterhouse</p>

<ul>
<li>Technical debt compounds in a way that is painful</li>
</ul>


<h2>Localization</h2>

<ul>
<li>get them early, reference labels -> will make it so much easier
later</li>
<li>no words in logos or images</li>
</ul>


<h2>Distributon</h2>

<h2>Security</h2>

<ul>
<li>use 3rd party people that do this</li>
<li>leave room for encryption</li>
<li>sunset your data after a certain period</li>
</ul>


<h2>Extensibility</h2>

<ul>
<li> make your work modifiable</li>
</ul>


<h2>Documentation</h2>

<ul>
<li>documentation helps us with onboarding and reduces context switches
for seniors</li>
<li>production scripts and build sequences need to be recorded</li>
</ul>


<h2>Affordance</h2>

<ul>
<li>tells us what we are doing without documentation</li>
</ul>


<h2>Acceptance</h2>

<ul>
<li>have you showed this product to anyone who is like the user (not the
financiers) -> need to actually talk to them</li>
<li>show them the product and don&#8217;t tell them how it supposed to work is
the hardest and most important part</li>
<li>&#8220;Making users awesome&#8221; - people don&#8217;t want to be using software,
they want to be drawing or taking a photograph, software is just an
intermediary</li>
</ul>


<h2>Accessiblity</h2>

<ul>
<li>look at this on a non-retina screen</li>
<li>emulators and physical are totally different experiences</li>
<li>8% of men are red-green color blind</li>
<li> status updates for nagios use red-green, which isn&#8217;t helpful</li>
<li>hide your mouse, use TAB instead</li>
<li>we are all temporarily able-bodied</li>
</ul>


<h2>Tactics</h2>

<ul>
<li>Learn how to write ROI documents</li>
<li>diverse teams will help with these problems</li>
<li>money is the root of all business decisons</li>
<li>be productively lazy</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Databases with Brad Urani]]></title>
    <link href="http://adamjonas.com/blog/databases-with-brad-urani/"/>
    <updated>2017-03-09T08:42:00-05:00</updated>
    <id>http://adamjonas.com/blog/databases-with-brad-urani</id>
    <content type="html"><![CDATA[<p>Brad Urani @confoo</p>

<h3>ACID -></h3>

<ul>
<li>atomicity: all or nothing. If one of 3 writes fails it rolls it back</li>
<li>Consistency:</li>
<li>Isolation:</li>
<li><p>Durability: DB survives</p></li>
<li><p>no-sql aren&#8217;t faster because of algorithms, they are faster because they did it because they did away with the guarantees</p></li>
</ul>


<p>google spanner - reliable network because it&#8217;s with in their own fiber optics</p>

<h3>SQL is declarative language</h3>

<ul>
<li>don&#8217;t give the computer exact instructions. Giving the comp a rough outline and the DB.</li>
</ul>


<h3>index is a tree</h3>

<ul>
<li>binary tree</li>
<li>doubled the size of the tree but only increased by 33%  - O(log n)</li>
<li>balanced tree -> rebalancing in order to make it as fast as possible</li>
<li>why not add indexes to everything

<ul>
<li>disk space and inserts</li>
</ul>
</li>
</ul>


<h3>Quick sort</h3>

<ul>
<li>fastest, but not that fast for records on disk</li>
</ul>


<h3>Merge sort</h3>

<ul>
<li>divide and conquor algorithm</li>
<li>O(n log n)</li>
</ul>


<h3>Joins:</h3>

<ul>
<li>nested loop JOINs - O(n<sup>2)</sup></li>
</ul>


<h3>Hash Join -> O(n)</h3>

<ul>
<li>Hash tables -> values are pointers because they are in linked lists

<ul>
<li>building the hash table from the beginning is expensive.</li>
<li>MD5? go with a bit key that doesn&#8217;t guarantee no collisions</li>
</ul>
</li>
<li>good for lots of duplicates</li>
</ul>


<h3>Merge Join -> O(m log n)</h3>

<ul>
<li>lists are already sorted.</li>
</ul>


<h3>Query plans</h3>

<ul>
<li>explain or explain analyze -> can tune the query to be faster</li>
</ul>


<h3>natural selection process for finding the best query plan</h3>

<ul>
<li>like genetic selection</li>
<li>doing all this in milliseconds</li>
<li>Evaluation -> selection -> crossover -> mutation</li>
</ul>


<h3>Caching</h3>

<ul>
<li>cache warmup period</li>
<li>Least recently used (LRU) in memory cache</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Working to Make Myself Obsolete]]></title>
    <link href="http://adamjonas.com/blog/working-to-make-myself-obsolete/"/>
    <updated>2016-11-26T12:23:00-05:00</updated>
    <id>http://adamjonas.com/blog/working-to-make-myself-obsolete</id>
    <content type="html"><![CDATA[<p>When I told my mother, an executive of 30 years mostly spent at <a href="http://www.crabtree-evelyn.com/">Crabtree and Evelyn</a>, about my goal to make myself obsolete she flipped.</p>

<p>&#8220;You are working yourself out of your job,&#8221; she warned. &#8220;You need to be doing the opposite.&#8221;</p>

<p>My mom fought through sexism for decades to maintain her influential role at the top of the hierarchy. My mother is a scrapper and she clearly had to defend her territory. From her advice on management issues however, it seems pretty clear to me she probably never got ahead of the tsunami of work that consumes managers’ everyday lives. I mostly observe managers fire fighting and doing implementation. This is a trap. We all want to feel important, but if managers are the single point of failure, things will fall apart.</p>

<p>I’ve mused about my take on <a href="http://adamjonas.com/blog/my-take-on-maker-versus-manager/">maker versus manager</a>, it can be hard to let go, but those that never let go of the hybrid role are doomed. The manager may not be, but the team is. We owe it to our reports to make sure we have the time to properly manage them. It feeds our egos to have a full calendar and lots of “important” decisions to make, but if that’s all we do then we will eventually drown in our own self-importance rather than develop the people on our team to help shoulder the load. Scale will break us.</p>

<p>So thanks mom for the advice, but I still strive to make myself obsolete, so the world will continue to spin without me. So I can go on vacation without stressing. So I can dedicate a good chunk of my week to 1 on 1s and so my lieutenants feel qualified and empowered to make the calls shape our team and product. I may be working myself out of a job, but at least I feel like I’m going to do this one right.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[New Technology and Developer Happiness]]></title>
    <link href="http://adamjonas.com/blog/new-technology-and-developer-happiness/"/>
    <updated>2016-11-15T12:24:00-05:00</updated>
    <id>http://adamjonas.com/blog/new-technology-and-developer-happiness</id>
    <content type="html"><![CDATA[<p>What is the price worth paying to introduce a new technology into the stack? For our heavily junior team of 13 the price feels high. Our JS weapon of choice has been backbone and marionette. This toolset wasn’t determined by me. It was molded and implemented by a talented dev who might be a little short on leadership experience but has talent and intuition in spades. We’ve made some mistakes along the way, but the architectural choices he has made have served us well. Still about 8 months since its we push our first major feature set with marionette, the entire team has yet to be completely onboarded. We may be getting to the size where we can split our squad into front-end and back-end specialists, but to date that has never been discussed as a group. The fact that we all haven’t got there is a problem. It means that some of us aren’t capable to work on parts of the stack, which affects feature assignments and pairing.</p>

<p>This same dev is now suggesting that we introduce React to one aspect of the stack because of its rising popularity in the community. Our team spends a lot of time focusing on happiness at an individual level with 1 on 1s and <a href="http://adamjonas.com/blog/quarterlies/">quarterlies</a>, but my priority isn’t individual happiness but rather team morale. At the moment, team morale is at an all-time high. Will introducing a new barrier to entry positively affect team morale because of its shiney? Will allowing the two JS leads on the team play with a new toy positively affect team morale? They both claimed in their last quarterly that their work brought them high levels of meaning and purpose and they found it challenging enough.</p>

<p>It is a tough call. I don’t have enough knowledge to know if this is truly a better tool or something new to learn for the sake of something new. How will we go about leveling up newcomers on two JS systems?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Goal Setting for Devs]]></title>
    <link href="http://adamjonas.com/blog/goal-setting-for-devs/"/>
    <updated>2016-10-11T10:05:00-04:00</updated>
    <id>http://adamjonas.com/blog/goal-setting-for-devs</id>
    <content type="html"><![CDATA[<p>I heard you, goals are important. I get it. I&#8217;ve watched the Ted talks and read the zillionth article on the importance of goals. I understand the psychology and the physiology. I’ve got a dirty secret though. I haven’t been able to set goals for developers. We’ve tried KPIs and they don’t seem to filter down to the individual contributor level. When I ran our apprenticeship program two years ago I tried weekly goals, bi-weekly goals, monthly goals and quarterly goals. The problem was, the constants, the areas the goals could be clearly defined were mostly areas of personal development &#8211; writing blog posts, learning keyboard shortcuts, giving a lunch and learn, etc. I had a much harder time defining goals for them to improve in their core job function, namely contributing well built features and pushing good code.</p>

<p>Recently we took a shot at changing our criteria for hiring and job responsibilities to being value based rather than bring task or milestone based. This rubric broke down our company values into behaviors and defined the expectations for each level within engineering. The resulting document sat well with the team and I think we are gettng closer, but I still can’t help but feel unfortable about the subjectivity of how to define a good productive dev. What devs do is complicated, which makes promotions and evaluation complicated. I don’t care whether you wrote a blog post this week if you pushed a great feature. I do care that you helped someone else push their feature or jumped in on a tough bug when everyone pretended they didn&#8217;t see it. But how do I formulate concrete actionable goals around that? Anything I come up with feels so arbitrary.</p>

<p>When we tried KPIs for the engineering team it made sense to have goals around the product. But for individual contributors who didn’t have a choice about what feature they build or how the product evolves from a high level, I could connect them to the department goal in a meta way, but not on an individual basis. How could they be held responsible for the adoption success a feature set, for example, that they didn’t have much agency in designing or implementing?</p>

<p>The best I can do for goal setting is to pull out actionable points from our <a href="http://adamjonas.com/blog/quarterlies/">longer-arching conversations</a> and hold them accountable on the things that matter to them both. It feels like there has to be something better, but I haven&#8217;t been smart enough to figure it out.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Quarterlies]]></title>
    <link href="http://adamjonas.com/blog/quarterlies/"/>
    <updated>2016-10-03T11:54:00-04:00</updated>
    <id>http://adamjonas.com/blog/quarterlies</id>
    <content type="html"><![CDATA[<p>Weekly 1 on 1s are not enough. Maybe if I did them better they would be, but mine are all on Fridays and often I’m not able to tease out anything more than the day to day updates and feelings of the past week. That’s not to say that I’m going to stop, 1 on 1s keep me connected to my reports and even if 1 out of every 5 is a breakthrough session then it is time very well spent.</p>

<p>The problem that I see in 1 on 1s as I run them is that it is hard to focus on the longer arching themes on a weekly basis. For whatever reason, it feels awkward to ask about career goals, work fulfillment, etc. with such regularity. Enter the quarterly. I’ve just completed my fourth attempt of quarterlies (not including the annual review). I’m happy with the conversations and the depth of the issues we discuss in those session but my attempt at this didn’t start very well.</p>

<p>Here were the set of questions from the first quarterly survey which I conducted using google forms:</p>

<ul>
<li>How happy are you in labs?</li>
<li>I feel like I&#8217;m growing my skills</li>
<li>I get clear and frequent feedback about my performance?</li>
<li>Given the products we are building, what types of things do you want to work on?</li>
<li>What skills (on or off the keyboard) do you want to improve that you don&#8217;t see an opportunity to do in your current role?</li>
<li>I understand why we are building Learn and the related apps</li>
<li>If you answer that you get it, please summarize why we are putting so much work into Learn.</li>
<li>If you answered you don&#8217;t get it, please tell me what needs further explanation.</li>
<li>Anything else you want to discuss?</li>
<li>What is one thing that would make you happier or more productive?</li>
</ul>


<p>This caused a lot of anxiety. Why am I doing this? What was I going to use this information for? Many of those first conversations were stilted, even confrontational. Someone actually took this time to give his two week notice. It wasn’t pretty. Even so, I was able to battle through these difficult conversations and pull out a lot of agenda topics that we were able to resolve as a group. This made it all worthwhile. Gathering the team in the room to talk about issues that were affecting all of us and re-focus our direction was incredibly fruitful. I also followed up with the individuals that took issue with the set of questions I was asking and had them help me craft a questionnaire that was easier for them to swallow.</p>

<p>Three month later the process went much smoother. Here were the revised questions.</p>

<ul>
<li>I feel like I&#8217;m growing my skills</li>
<li>What is one thing that would make you happier or more productive?</li>
<li>In what ways would you like to grow your skills? What kind of support will you need?</li>
<li>Do you feel like you’re getting enough clear feedback?</li>
<li>How do you feel about the Lab&#8217;s processes in general?</li>
<li>Given the products we are building, what types of things do you want to work on?</li>
<li>I find the work that I do full of meaning and purpose</li>
<li>I am proud of the work that I do for my team</li>
<li>The work that I do is challenging</li>
<li>How would you rate yourself in the following 4 tenets of our “shipping culture” (circle one for each category):</li>
<li>Velocity</li>
<li>Quality</li>
<li>Ownership</li>
<li>Communication</li>
</ul>


<p>This one clicked much better. I got great responses and we had a great team discussion. Processes changed, people were engaged and excited to debate with each other. I was able to present the group with statistics on aggregated stats on how challenged individuals felt and where we needed to improve as a group.</p>

<p>A year later, this is the best thing I think I do as a manager. We ask similar long form answers but have dropped the ratings of the department values in lieu of the company values (see future post on Value Based Assessments). With a young team, it isn’t uncommon for me to see career aspirations change quarter along with engagement and performance. I’ve found these quarterlies to be better discussions than the annual review. Some reasons might be, it isn’t as formal or mired in the connotations of a scary end of year process. I use google forms rather than some HR software, which seems pretty natural and lightweight for devs. I choose a venue that seems more informal but is still off-site (recently I’ve been camping out at Au Bon Pain). And yet, much of this conversation is spent on discussing performance, areas of improvement, how to grow, resetting expectations and ways to improve the team and product &#8211; all the things that I would imagine a good annual review process is supposed to do. This cycle I’ve scheduled 90 minutes for each session but not one actually was completed in time. People are talking for 2 to 2 ½ hour stretches even though it is basically the same set of questions that I’ve used for the last three rounds. This is a huge investment of time. All said and done I will have done more than 30 hours of quarterlies before preparing a deck we can discuss as a group. But this is working and the conversations have improved every quarter.</p>

<p>Even with its rocky start, quarterlies have served us well. I would have never known many of the team’s process pain points without these conversations and it has saved me when performance slips so that I can get on the record to address it quickly. If annual reviews are broken my first guess would be that even if they are conducted well, they are just too infrequent. Things on my team move too quickly to address on a 12-month cycle. This is my best shot at making it better.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[When I didn't see it in the interview]]></title>
    <link href="http://adamjonas.com/blog/when-i-didnt-see-it-in-the-interview/"/>
    <updated>2016-09-28T11:46:00-04:00</updated>
    <id>http://adamjonas.com/blog/when-i-didnt-see-it-in-the-interview</id>
    <content type="html"><![CDATA[<p>Raw intellect isn’t enough. Just like product market fit we need to see person-job fit. How can we test it? Good people with drive and patience for change and a healthy sense of duty seem to be able to adjust to nearly any job for a short period. We can all do any job for six months and knock it out of the park.</p>

<p>I think about a particular interview where I left so excited about the candidate. They were quirky, but thoughtfully engaged. They grasped what we did here and why it was important. They thirsted for new knowledge and challenge. They were young and ambitious. No work experience of any kind.</p>

<p>But when he arrived it was an utter let down. The focus wasn’t on getting as good as possible as quickly as possible but rather maintaining balance at all times. Never pushing himself to be in the trenches with his brethren in times as the pressure bore down on them or let the passion take him deep into the night when we feel the torment of an unfinished idea demanding completion.</p>

<p>All the raw materials were there. What did I miss? If we hire someone with no work history, does the onboarding process need to be different? Do we need to teach them not only how to do the job but also how to be an employee? What expectations did we set to encourage him to rise to be great?</p>

<p>I cannot move past my disappointment. I signed off on him. I had high expectations. Though not my direct report, I provided course corrections. As time continues to march on the disappointment builds. I notice the small improvements but never the grand about-face for which I hold out hope. That one day when he will wake up, open his eyes to observe and finally be dissatisfied with his mediocrity.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Transparency]]></title>
    <link href="http://adamjonas.com/blog/transparency/"/>
    <updated>2016-09-20T12:21:00-04:00</updated>
    <id>http://adamjonas.com/blog/transparency</id>
    <content type="html"><![CDATA[<p>Transparency begets trust and trust begets transparency. It isn’t easy and it feels unsafe to bare your process and sometimes soul. Talking about the thing you least want to talk about has been something that has helped our team address the weirdness that exists between our people and processes. But it wasn’t always like this. We used to ignore or only privately address what needed to be discussed the most.</p>

<p>A few months ago, during a period when a lot of new hires were starting and suffering from imposter syndrome, I tried to reinforce our culture of transparency and honesty by telling my team that I wouldn’t hire myself for our team. I assume that isn’t something that most managers admit and I explained my rationale. I’m not a strong enough coder to hang with them. I don’t complement the personalities we have. I don’t bring enough of a unique perspective as an individual contributor. It pains me to even write this, let alone tell my teammates that this is how I feel. Doing this led to a bunch of other team members describing their version of <a href="https://en.wikipedia.org/wiki/Impostor_syndrome">imposter syndrome</a> and clearly put the junior members at ease. That is all to say, that saying the thing I least wanted to say helped build trust with the newest folks and let them know what I worry about which means they can be more sure when I’m confident. Always acting one way or another isn’t natural. Transparency, therefore, may start with the act of humanizing yourself and being vulnerable.</p>

<p>Team buy-in is tough to earn. It is much easier when the process is created and enforced by the team. As the manager, I can try to keep it on guardrails, but determining it and enforcing it myself would be a mistake. Maybe this isn’t sustainable with a bigger team. What if all the laws in this country were determined democratically by the entire population. It would be way too heavy. But with a team of 13, this is still possible and it is so much stronger when the policing is done by the team rather than me.</p>

<p>Transparency communicates trust. Exposing our vulnerabilities as an individual or an organization encourages candor and self-reflection. Putting a positive spin on everything doesn’t equate to boosted morale because it leads to whispers, eye rolling and eyebrow raising in the hallways. It is human nature to latch onto weaknesses, failures, and negatives and so if these deficiencies are not squashed publicly then they fester. They use rumors as sustenance and mutate in unpredictable ways. Talking about the hardest things right away is painful, but a preferable alternative to passively deferring to hearsay.</p>

<p>Transparency is hard. Generals must be able to make decisions. Soldiers must follow orders. We run into trouble is when soldiers don’t buy into the purpose or mission. Even the most ardent followers will lose enthusiasm over time if they don’t feel like they can influence the decision making process. And so what we find is people will do enough to keep their job. They half-heartedly go through the motions. In short order, that becomes the norm and apathy is a difficult virus to contain. And so while we can&#8217;t ask everyone for their input on every decision, if we know what is important to our people, we can ask them at the right times. This requires the decision maker to actually know their people and that takes a serious investment. Do you have time for that? I guess that&#8217;s up to you, but second guessing, rumor squashing, and low-morale also eats up time so maybe this would be worth some investment.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Peer Mentorship]]></title>
    <link href="http://adamjonas.com/blog/peer-mentorship/"/>
    <updated>2016-09-01T09:55:00-04:00</updated>
    <id>http://adamjonas.com/blog/peer-mentorship</id>
    <content type="html"><![CDATA[<p>Next week I’m going to introduce a new 1 on 1 system on our team. I currently have 8 reports and the other manager on our team has 5. The load of weekly 1 on 1s is quite large if we are truly doing a legitimate check-in. And so, I’d like to try out a system of peer mentorship where peers conduct one on ones with each other for a week to 2 weeks a month. This means we will need to spend time training the team on how to conduct 1 on 1s which I will assume will force us to consider how we currently conduct our 1 on 1s and how they could be better.</p>

<p>Peer mentorship organically already exists on the team. We see natural gravitations along lines of technological specialities and personality types. I’ve done my best to find assignments for these pairs to share a chunk of time working together and I’ve always been impressed with the results. Formalizing this process through this peer mentorship check-in system should further reinforce that natural alliance without forcing devs to be people managers.</p>

<p>We’ll see how this experiment works out, but I’m excited to give it a try. Trusting team members with the task of developing their peers has almost always led to positive results. I expect the same here.</p>
]]></content>
  </entry>
  
</feed>
